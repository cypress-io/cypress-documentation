---
title: Experiments
---

If you'd like to try out what we're working on in Cypress, you can enable
specific experimental features for your project using the Cypress configuration
options described below.

:::caution

⚠️ The experimental features might change or ultimately be removed without
making it into the core product. Our primary goal for experiments is to collect
real-world feedback during their development. For more information, see the
documentation for all
[Cypress Release Stages](/guides/references/release-stages).

:::

## Configuration

You can pass the [Cypress configuration](/guides/references/configuration)
options below to enable or disable experiments. See our
[Configuration Guide](/guides/references/configuration) on how to pass
configuration to Cypress.

| Option                                        | Default | Description                                                                                                                                                                                                                                                                                                                    |
| --------------------------------------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `experimentalCspAllowList`                    | `false` | Indicates the Content-Security-Policy directives to be permitted during a test run. See [Content-Security-Policy](/guides/guides/content-security-policy) for more information.                                                                                                                                                |
| `experimentalFetchPolyfill`                   | `false` | Automatically replaces `window.fetch` with a polyfill that Cypress can spy on and stub. Note: `experimentalFetchPolyfill` has been deprecated in Cypress 6.0.0 and will be removed in a future release. Consider using [cy.intercept()](/api/commands/intercept) to intercept `fetch` requests instead.                        |
| `experimentalInteractiveRunEvents`            | `false` | Allows listening to the [`before:run`](/api/plugins/before-run-api), [`after:run`](/api/plugins/after-run-api), [`before:spec`](/api/plugins/before-spec-api), and [`after:spec`](/api/plugins/after-spec-api) events in the [setupNodeEvents](/guides/tooling/plugins-guide#Using-a-plugin) function during interactive mode. |
| `experimentalMemoryManagement`                | `false` | Enables support for improved memory management within Chromium-based browsers.                                                                                                                                                                                                                                                 |
| `experimentalModifyObstructiveThirdPartyCode` | `false` | Whether Cypress will search for and replace obstructive code in third party `.js` or `.html` files. NOTE: Setting this flag removes [Subresource Integrity (SRI)](https://developer.mozilla.org/en-US/docs/Web/Security/Subresource_Integrity).                                                                                |
| `experimentalSourceRewriting`                 | `false` | Enables AST-based JS/HTML rewriting. This may fix issues caused by the existing regex-based JS/HTML replacement algorithm. See [#5273](https://github.com/cypress-io/cypress/issues/5273) for details.                                                                                                                         |
| `experimentalWebKitSupport`                   | `false` | Enable experimental support for running tests in WebKit. When set, installs of `playwright-webkit` will be detected and available in Cypress. See [Launching Browsers](/guides/guides/launching-browsers#WebKit-Experimental) for more information.                                                                            |
| `retries.experimentalStrategy`                | N/A     | Applies a strategy for test retries according to your "flake tolerance"; options are detect-flake-but-always-fail or detect-flake-and-pass-on-threshold. See [Experimental Retries](/guides/references/experiments#Experimental-Test-Retries) for more details.                                                                |
| `retries.experimentalOptions`                 | N/A     | Sets retries strategy-specific options like maxRetries, passesRequired, and stopIfAnyPassed. See [Experimental Retries](/guides/references/experiments#Experimental-Test-Retries) for more details.                                                                                                                            |
| `experimentalBurnIn`                          | `false` | Enables burn-in for Flake Detection on Cypress Cloud. See [Experimental Burn-in](/guides/references/experiments#Experimental-Burn-in) for more details.                                                                                                                                                                        |

### Experimental CSP Allow List

Cypress by default strips all CSP headers (`Content-Security-Policy` and
`Content-Security-Policy-Report-Only`) from the response before it is sent to
the browser. The `experimentalCspAllowList` option allows for more granular
control over which CSP directives are stripped from the CSP response headers,
allowing you to test your application with CSP enabled. Valid values for this
option are `false` (the default), `true`, or an array of CSP directive names.

| Value                                                 | Example                                                 |
| ----------------------------------------------------- | ------------------------------------------------------- |
| [`false` (default)](#Strip-All-CSP-Headers)           | `experimentalCspAllowList=false`                        |
| [`true`](#Strip-Minimum-CSP-Directives)               | `experimentalCspAllowList=true`                         |
| [`<CspDirectives>[]`](#Allow-Specific-CSP-Directives) | `experimentalCspAllowList=["default-src","script-src"]` |

#### Strip All CSP Headers

The value `experimentalCspAllowList=false` (default) will remove all CSP headers
from the response before it is sent to the browser. This option should be used
if you do not depend on CSP for any tests in your application.

#### Strip Minimum CSP Directives

If you need to test your application with CSP enabled, setting the
`experimentalCspAllowList` option will allow all CSP headers to be sent to the
browser _*except*_ those that could prevent Cypress from functioning normally.

The following CSP directives will always be stripped:

| Stripped Directive          | Allowable | Reason                                                           |
| --------------------------- | --------- | ---------------------------------------------------------------- |
| `frame-ancestors`           | No        | Prevents Cypress from loading a test application into an iframe. |
| `navigate-to`               | No        | Affects Cypress' ability to navigate to different URLs.          |
| `require-trusted-types-for` | No        | Might prevent Cypress from rewriting the DOM.                    |
| `sandbox`                   | No        | Can restrict access to script and iframe functionality.          |
| `trusted-types`             | No        | Could cause Cypress injections to be marked as untrusted.        |

When `experimentalCspAllowList=true` the following directives are also stripped
in addition to the ones listed above, but can be configured to be allowed to be
sent to the browser:

| Stripped Directive | Allowable | Reason                                                                        |
| ------------------ | --------- | ----------------------------------------------------------------------------- |
| `child-src`        | Yes       | Could prevent iframes from loading in combination with other Cypress options. |
| `default-src`      | Yes       | Conditionally prevents Cypress from loading scripts and running.              |
| `frame-src`        | Yes       | Could prevent iframes from loading in combination with other Cypress options. |
| `form-action`      | Yes       | Can prevent Cypress from monitoring form events.                              |
| `script-src`       | Yes       | Conditionally prevents Cypress from loading scripts and running.              |
| `script-src-elem`  | Yes       | Conditionally prevents Cypress from loading scripts and running.              |

#### Allow Specific CSP Directives

Set the `experimentalCspAllowList` option to an array of directive names marked
as "Allowable" from the list above. This will allow the specified CSP directives
to be sent to the browser.

The following configuration would allow the `default-src`, `script-src`, and
`script-src-elem` directives to be sent to the browser:

:::cypress-config-example

```js
{
  experimentalCspAllowList: ['default-src', 'script-src', 'script-src-elem']
}
```

:::

:::caution

Defining `experimentalCspAllowList` _*may*_ cause Cypress to be unable to run
tests against your application. If you experience issues, reduce the directives
specified in your allow list to identify which directive is causing issues.

There is a known issue when using certain directives containing hash algorithm
values and the `modifyObstructiveCode` and/or `experimentalSourceRewriting`
options. Using these options in combination with the `experimentalCspAllowList`
option can cause a mismatch between the original hashed directive value, and the
modified HTML or JS value.

:::

## Experimental Flake Detection Features

End-to-end (E2E) tests excel at testing complex systems. However, there are
still behaviors that are hard to verify and make tests flaky (i.e., unreliable)
and fail sometimes due to unpredictable conditions (eg., temporary outages in
external dependencies, random network errors, etc.). Some other common race
conditions that could result in unreliable tests include:

- Animations
- API calls
- Test server / database availability
- Resource dependencies availability
- Network issues

Flaky tests can be challenging to identify and resolve, due to their behavior being non-deterministic and therefore not always easy to reproduce. Burn-in is an experimental feature to identify flaky tests as well as achieve greater confidence with presumably "not flaky" tests. Test retries can also detect flake, though to a lesser degree.

### Experimental Burn-in

[Test retries](/guides/guides/test-retries) is a Cypress [Flake Detection](/guides/cloud/flaky-test-management#Flake-Detection) feature that *reactively* finds flake on tests that initially failed. However, this offers no solution for a flaky test which initially passes.

Test Burn-in is an experimental feature for *proactively* detecting flake on new, modified, and previously flaky or failing tests. These tests demonstrate the highest risk for flaky behavior, since they either represent code changes or have yet to pass consistently. Burn-in therefore increases your confidence in these test's flake status.

:::tip

<strong>
  <Icon name="star" /> Premium Cypress Cloud Feature
</strong>

**Experimental test burn-in** is available to users with at least a
[Team Cypress Cloud plan](https://cypress.io/pricing).

:::

You can enable burn-in with this configuration in your Cypress config.

:::cypress-config-example

```js
{
  experimentalBurnIn: true
}
```

:::

#### New and modified tests

When dealing with flaky tests within a team, rapid detection is key. A flaky test creates more headache the longer it persists. For example, you see your new test is passing today, and you commit and merge it. A few days later, one of your teammates sees it fail and doesn't know if something else changed in the code or the environment to cause the failure. The test could have been flaky since the beginning, and you just got lucky on your test run. It's challenging to isolate the root causes of flake in these cases, which is why many teams add flaky tests to their list of "tech debt" issues.

This is where burn-in comes in handy, by ensuring any new or modified test is consistently passing. If it isn't, whoever updated or added the test will discover the test's flakiness as soon as the test runs, instead of several runs later, when they have moved on to another feature or project and don't have the bandwidth to revisit this test.

When enabled, burn-in will verify all new and modified tests will pass 3 consecutive attempts on a single run. For example:

**Burn-in Scenario 1:**

*New test*

- Attempt 1: <Icon name="check-circle" color="green" /> Pass
- Attempt 2: <Icon name="check-circle" color="green" /> Pass
- Attempt 3: <Icon name="check-circle" color="green" /> Pass

The new test has passed all 3 burn-in attempts, and therefore is **not flaky**.

#### Previously flaky or failing tests

If a test failed in a previous run, you should be wary once it manages to pass. It's best to demonstrate consistently passing behavior, which is why burn-in also applies in this situation. Similarly, when tests are flaky, they are burned-in with extra scrutiny to ensure that a passing result has overcome a previously flaky status.

Burn-in will verify all previously failing tests will pass 3 consecutive attempts on a single run, and that previously flaky tests will pass 5 consecutive attempts in a single run. For example:

**Burn-in Scenario 2:**

*Previously flaky test*

- Attempt 1: <Icon name="check-circle" color="green" /> Pass
- Attempt 2: <Icon name="check-circle" color="green" /> Pass
- Attempt 3: <Icon name="check-circle" color="green" /> Pass
- Attempt 4: <Icon name="check-circle" color="green" /> Pass
- Attempt 5: <Icon name="check-circle" color="green" /> Pass

The test has passed all 5 burn-in attempts, and therefore is **no longer flaky**.

#### What happens when a test fails during the burn-in attempts?

If a test fails on any of the burn-in attempts after the initial passing attempt, then you know the test is flaky. 

After that, the test will default to [test retries](/guides/guides/test-retries) to determine the passing or failing result of the test. It's recommended to use [experimental retries](/guides/references/experiments#Experimental-Test-Retries) when using burn-in, which offer more control over flaky test's final results and flake detection behaviors in the case of failing tests.

Here's an example of how a flaky test might execute with burn-in and experimental retries:

**Burn-in Scenario 3:**

Configuration on burn-in and retries:

:::cypress-config-example

```js
{
  experimentalBurnIn: true,
  retries: {
    experimentalStrategy: `detect-flake-and-pass-on-threshold`,
    experimentalOptions: {
      maxRetries: 2,
      passesRequired: 2
    },
    openMode: true,
    runMode: true
  }
}
```

:::

*New test*

- Attempt 1: <Icon name="check-circle" color="green" /> Pass
- Attempt 2: <Icon name="times" color="red" /> Fail (burn-in stops here; retries now take-over and this 2nd burn-in attempt counted as the 1st retry attempt, so only 1 retry attempt remains due to `maxRetries: 2`)
- Attempt 3: <Icon name="check-circle" color="green" /> Pass (retries stop here; the test has met the `passesRequired: 2` threshold)

The new test did not pass all attempts, so it is **flaky**. However it did meet the `passesRequired: 2` threshold, so it is also **passing**.

If the test fails on the initial attempt, then test retries will also execute instead of burn-in.

#### Is it recommended to use burn-in with test retries also enabled?

Yes, because test retries will ensure you can still detect flake on tests which initially fail.

Also, unless you want every flaky test to be considered passing (instead of failing), you should use the [experimental test retries feature](/guides/references/experiments#Experimental-Test-Retries) to configure how you would like flaky tests to be counted in terms of passing or failing results.

#### What if I want to specify other numbers of attempts for the various burn-in scenarios?

:::tip

<strong>
  <Icon name="star" /> Premium Cypress Cloud Feature
</strong>

**Custom settings for experimental test burn-in** is available to users with at least a
[Business Cypress Cloud plan](https://cypress.io/pricing).

:::

You can specify different settings using this configuration:

:::cypress-config-example

```js
{
  experimentalBurnIn: {
    default: 3,
    flaky: 5
  }
}
```

:::

These two settings, `default` and `flaky`, correspond to these conditions where burn-in applies:
- `3` attempts (`default`) for new, modified, and previously failing tests
- `5` attempts (`flaky`) for previously flaky tests

You can change any of these settings by updating either of them to any integer greater than 1.

#### What if I want to ignore or skip "old" or "known" flaky tests and only burn-in for "new" flake?

Perhaps you have some "known flaky" tests that your team has ignored for a while, and you want to just ignore them.

In this case, it's recommended to address these tests such that they are no longer flaky. It's a non-deterministic test that does not give confidence in the test's result. If the test cannot be fixed, then it's recommended to remove this test from your test runs so as to prevent the test from giving you false assurances.

#### How do I enable burn-in only for specific branches or test runs? Or specific tests?

Burn-in is configured at the Cypress project level. It therefore cannot be configured for specific tests or specs.

It can be configured on a per-run basis. For example, you can use the [Cypress API/CLI](/guides/guides/module-api#cypresscli) to specify different burn-in configurations for your feature branch runs versus your main/default branch runs.

If you would like to provide us with feedback about these levels of configuration for burn-in, please let us know. *(Feedback form coming soon)* It's an experimental feature, so we certainly appreciate all the feedback we can get.

#### How do you determine the test's history/lineage for the purposes of burn-in?

*Coming soon: FAQ on how Cypress Cloud tracks test history*

#### Is there any UI in Cypress Cloud to help understand the burn-in behavior and results?

There are a number of [Flake Management](/guides/cloud/flaky-test-management#Flake-Detection) features currently available to help your team deal with the flaky tests and see how any improvements are doing. As burn-in is still an experimental feature, we're also actively working on further UI updates to Cypress Cloud. 

In the meantime, if you have any suggestions for burn-in features in Cloud, please let us know. *(Feedback form coming soon)*

### Experimental Test Retries

[Test retries](/guides/guides/test-retries) is a Cypress [Flake Detection](/guides/cloud/flaky-test-management#Flake-Detection) feature that enables you to re-attempt any tests that initially fail. The failure may not be a "true" failure, i.e. flaky. The only way to determine this is to retry the test.

Normally, test retries simply stop on the first passing attempt. And the final test result of any flaky test is always "passing", irregardless of how many prior attempts failed. The following experimental settings for retries give you more control over the retries process.

There are two strategies for retries:

- `detect-flake-and-pass-on-threshold`
- `detect-flake-but-always-fail`

The `detect-flake-and-pass-on-threshold` strategy is most like the current implementation of retries, where failing tests have a "chance" to still pass, but still detect flake. But this new experimental strategy also enables you to now set a threshold of passing attempts to achieve a passing final result. And if you want to ensure flaky tests are treated with the same urgency as failing tests, then you will prefer to use the `detect-flake-but-always-fail` strategy, which assures that every flaky test is still marked as failing.

#### `experimentalStrategy: 'detect-flake-and-pass-on-threshold'`

Setting `experimentalStrategy: 'detect-flake-and-pass-on-threshold'` within retries will give you ability to set how many passing attempts are required for the test result to be passing. There are two `experimentalOptions` that must be set with this strategy:

- `maxRetries` sets the maximum number of retries that can occur after the first attempt failed
- `passesRequired` sets the required number of passing attempts for the final test result to be passing. Cannot be greater than `maxRetries`.
  - `passesRequired` also determines how the retries may stop before `maxRetries` is reached; either if the number of passing attempts so far has met the `passesRequired` condition or if the number of failing attempts exceeds the difference between `maxRetries` and `passesRequired` (when it's impossible to achieve the passing result).

:::cypress-config-example

```js
{
  retries: {
    experimentalStrategy: 'detect-flake-and-pass-on-threshold',
    experimentalOptions: {
      maxRetries: 2,
      passesRequired: 2
    },

    // you must also explicitly set openMode and runMode to
    // either true or false when using experimental retries
    openMode: true,
    runMode: true
  }
}
```

:::

Examples of the above configuration's results:

**Scenario 1:**

- Attempt 1: <Icon name="times" color="red" /> Fail
- Attempt 2: <Icon name="check-circle" color="green" /> Pass
- Attempt 3: <Icon name="times" color="red" /> Fail

The retries stop on attempt 3, since `maxRetries: 2` is now met and the test's final result is **failing** <Icon name="times" color="red" /> and **flaky**. Only one attempt passed, but two are needed to pass.

**Scenario 2:**

- Attempt 1: <Icon name="times" color="red" /> Fail
- Attempt 2: <Icon name="check-circle" color="green" /> Pass
- Attempt 3: <Icon name="check-circle" color="green" /> Pass

Retries stop at attempt 3 again, and the test is **passing** <Icon name="check-circle" color="green" /> and **flaky**, since there are now two passing attempts.

**Scenario 3:**

- Attempt 1: <Icon name="times" color="red" /> Fail
- Attempt 2: <Icon name="times" color="red" /> Fail

Retries stop on attempt 2, and the test is **failing** <Icon name="times" color="red" />, because the requisite two passing attempts for a passing result can no longer be achieved once the 1st retry failed. It's also **not flaky**, since there were no passing attempts.

#### `experimentalStrategy: 'detect-flake-but-always-fail'`

Setting `experimentalStrategy: 'detect-flake-but-always-fail'` within retries ensures any test with any failed attempt will always end with a failing final result. There are two `experimentalOptions` that must be set in this strategy:

- `maxRetries` sets the maximum number of retries that can occur after the first attempt failed
- `stopIfAnyPassed` will stop the retries before `maxRetries` is reached when there is any passing attempt.
  - `stopIfAnyPassed` causes retries to exit as soon as any flake is detected (a test that is retrying after a failure only needs to pass once to exhibit flaky behavior). However it may help to see more retry attempts, such as when the failure mode is also non-deterministic and more of these different errors are revealed on more retries, in which case `stopIfAnyPassed: false` may be desirable.

:::cypress-config-example

```js
{
  retries: {
    experimentalStrategy: 'detect-flake-but-always-fail',
    experimentalOptions: {
      maxRetries: 2,
      stopIfAnyPassed: true
    },

    // you must also explicitly set openMode and runMode to
    // either true or false when using experimental retries
    openMode: true,
    runMode: true
  }
}
```

:::

Examples of the above configuration's results:

**Scenario 1:**

- Attempt 1: <Icon name="times" color="red" /> Fail
- Attempt 2: <Icon name="times" color="red" /> Fail
- Attempt 3: <Icon name="times" color="red" /> Fail

The retries stop on attempt 3, since `maxRetries: 2` is now met and the test is **failing** <Icon name="times" color="red" />, but also **not flaky**.

**Scenario 2:**

- Attempt 1: <Icon name="times" color="red" /> Fail
- Attempt 2: <Icon name="check-circle" color="green" /> Pass

Retries stop on the first retry, due to the passing attempt. The test is **failing** <Icon name="times" color="red" /> and **flaky**. If `stopIfAnyPassed` was `false`, then the retries would have proceeded once more.

:::caution

**Note:** Experimental retries can only be configured at the global level and **not** per individual test, whereas non-experimental `retries` [can be configured per test](/guides/guides/test-retries#Individual-Tests). If you configure retries on a per-test basis while using experimental retries globally, that particular test's `retries` configuration will override the experimental retries and ignore it.

Also, while using experimental retries, you cannot set numeric values for `openMode` or `runMode` [at the global level](/guides/guides/test-retries#Global-Configuration). You can instead set `true` or `false` for each.

:::

## Testing Type-Specific Experiments

You can provide configuration options for either E2E or Component Testing by
creating `e2e` and `component` objects inside your Cypress configuration.

### End-to-End Testing

These experiments are available to be specified inside the `e2e` configuration
object:

| Option                            | Default | Description                                                                                                |
| --------------------------------- | ------- | ---------------------------------------------------------------------------------------------------------- |
| `experimentalStudio`              | `false` | Generate and save commands directly to your test suite by interacting with your app as an end user would.  |
| `experimentalRunAllSpecs`         | `false` | Enables the "Run All Specs" UI feature, allowing the execution of multiple specs sequentially.             |
| `experimentalOriginDependencies`  | `false` | Enables support for `require`/`import` within `cy.origin`.                                                 |
| `experimentalSkipDomainInjection` | `null`  | Removes injecting `document.domain` into `text/html` pages for any sites that match the provided patterns. |

#### Experimental Skip Domain Injection

Under the hood, Cypress
[injects document.domain](/guides/guides/web-security#Examples-of-what-Cypress-does-under-the-hood)
into your test application to lessen the burden of navigation. This is well
described in our [Cross Origin Testing](/guides/guides/cross-origin-testing)
guide. However, some sites have compatibility issues with this feature.

The `experimentalSkipDomainInjection` option disables injecting
`document.domain` inside Cypress. When enabled, all cross-origin/subdomain
navigation must use `cy.origin()`, which may make tests a bit more verbose. We
only recommend including your site pattern if you are having issues running
Cypress out of the box and suspect setting `document.domain` is interfering with
your site's ability to render properly.

Before enabling, verify your application is not implementing frame busting
techniques, which you can mitigate with the
[`modifyObstructiveCode`](/guides/references/configuration#modifyObstructiveCode)
and
[`experimentalModifyObstructiveThirdPartyCode`](/guides/guides/web-security#Modifying-Obstructive-Third-Party-Code)
flags.

At this point in time, we are aware of the following sites that require the
`experimentalSkipDomainInjection` option to be set to be tested properly:

- Google
- Salesforce

This flag can be enabled by passing an array of origin URLs or
[minimatch](https://github.com/isaacs/minimatch) glob patterns:

:::cypress-config-example

```js
{
  e2e: {
    experimentalSkipDomainInjection: [
      '*.salesforce.com',
      '*.force.com',
      '*.google.com',
    ]
  }
}
```

:::

If using other Salesforce domains, such as
[enhanced domains](https://help.salesforce.com/s/articleView?id=sf.domain_name_enhanced.htm&type=5),
you will need to add the correct matching glob pattern.

### Component Testing

These experiments are available to be specified inside the `component`
configuration object:

| Option                         | Default | Description                                                                                                                                                                       |
| ------------------------------ | ------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `experimentalSingleTabRunMode` | `false` | Run all specs in a single tab, instead of creating a new tab per spec. This can improve run mode performance, but can impact spec isolation and reliability on large test suites. |

## History

| Version                                       | Changes                                                                                                                                       |
| --------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| [12.3.0](/guides/references/changelog#13-4-0) | Added support for configuring the Experimental Flake Detection strategy via `retries.experimentalStrategy` and `retries.experimentalOptions`. |
| [12.4.0](/guides/references/changelog#12-4-0) | Added `experimentalSkipDomainInjection` and `experimentalMemoryManagement`.                                                                   |
| [12.0.0](/guides/references/changelog#12-0-0) | Removed `experimentalSessionAndOrigin` and made it the default behavior. Added `experimentalOriginDependencies`.                              |
| [11.2.0](/guides/references/changelog#11-2-0) | Added `experimentalRunAllSpecs`.                                                                                                              |
| [10.8.0](/guides/references/changelog#10-8-0) | Added `experimentalWebKitSupport`.                                                                                                            |
| [10.6.0](/guides/references/changelog#10-6-0) | Added support for `experimentalSingleTabRunMode`.                                                                                             |
| [10.4.0](/guides/references/changelog#10-4-0) | Added support for `experimentalModifyObstructiveThirdPartyCode`.                                                                              |
| [9.6.0](/guides/references/changelog#9-6-0)   | Added support for `experimentalSessionAndOrigin` and removed `experimentalSessionSupport`.                                                    |
| [8.2.0](/guides/references/changelog#8-2-0)   | Added support for `experimentalSessionSupport`.                                                                                               |
| [7.1.0](/guides/references/changelog#7-1-0)   | Added support for `experimentalInteractiveRunEvents`.                                                                                         |
| [7.0.0](/guides/references/changelog#7-0-0)   | Removed `experimentalComponentTesting` and made it the default behavior.                                                                      |
| [6.7.0](/guides/references/changelog#6-7-0)   | Removed `experimentalRunEvents` and made it the default behavior.                                                                             |
| [6.3.0](/guides/references/changelog#6-3-0)   | Added support for `experimentalStudio`.                                                                                                       |
| [6.2.0](/guides/references/changelog#6-2-0)   | Added support for `experimentalRunEvents`.                                                                                                    |
| [6.0.0](/guides/references/changelog#6-0-0)   | Removed `experimentalNetworkStubbing` and made it the default behavior when using [cy.intercept()](/api/commands/intercept).                  |
| [6.0.0](/guides/references/changelog#6-0-0)   | Deprecated `experimentalFetchPolyfill`.                                                                                                       |
| [5.2.0](/guides/references/changelog#5-2-0)   | Removed `experimentalShadowDomSupport` and made it the default behavior.                                                                      |
| [5.1.0](/guides/references/changelog#5-1-0)   | Added support for `experimentalNetworkStubbing`.                                                                                              |
| [5.0.0](/guides/references/changelog#5-0-0)   | Removed `experimentalGetCookiesSameSite` and made it the default behavior.                                                                    |
| [4.9.0](/guides/references/changelog#4-9-0)   | Added support for `experimentalFetchPolyfill`.                                                                                                |
| [4.8.0](/guides/references/changelog#4-8-0)   | Added support for `experimentalShadowDomSupport`.                                                                                             |
| [4.6.0](/guides/references/changelog#4-6-0)   | Added support for `experimentalSourceRewriting`.                                                                                              |
| [4.5.0](/guides/references/changelog#4-5-0)   | Added support for `experimentalComponentTesting`.                                                                                             |
| [4.3.0](/guides/references/changelog#4-3-0)   | Added support for `experimentalGetCookiesSameSite`.                                                                                           |
